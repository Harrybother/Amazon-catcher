# -*- coding: utf-8 -*-
"""
firemaple_playwright.py
ä½¿ç”¨ Playwright çœŸæµè§ˆå™¨æŠ“å– Amazon AU å•†å“ä¿¡æ¯ï¼ˆæ‰‹åŠ¨ä¿®æ”¹åœ°å€ç‰ˆï¼‰
è¾“å‡ºå­—æ®µï¼šé“¾æ¥ / äºšé©¬é€ŠASIN / ä»·æ ¼ / ç±»ç›®&æ’å / è¯„åˆ† / åº—é“ºåç§° / æ˜¯å¦FBA / reviewæ•°é‡ / reviewæƒ…å†µ
"""

import asyncio
import re
import random
import pandas as pd
from bs4 import BeautifulSoup
from tqdm import tqdm
from playwright.async_api import async_playwright


# --------- å·¥å…·å‡½æ•° ---------
def clean_text(txt):
    if not txt:
        return "â€”"
    return re.sub(r"\s+", " ", txt).strip()


# --------- æ‰‹åŠ¨ä¿®æ”¹åœ°å€é€»è¾‘ ---------
async def set_au_delivery_address(page):
    """
    æ‰“å¼€ Amazon AU é¦–é¡µï¼Œç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨ä¿®æ”¹æ”¶è´§åœ°å€ã€‚
    ä¿®æ”¹å®ŒæˆåæŒ‰ Enter æˆ–åœ¨å‘½ä»¤è¡Œç¡®è®¤ç»§ç»­ã€‚
    """
    print("ğŸ”¹ æ­£åœ¨æ‰“å¼€ Amazon AU é¦–é¡µï¼Œè¯·æ‰‹åŠ¨å°†æ”¶è´§åœ°å€ä¿®æ”¹ä¸ºæ¾³æ´²ï¼ˆå»ºè®®é‚®ç¼– 2000ï¼‰...")
    print("   ä¿®æ”¹å®Œæˆåè¿”å›ç»ˆç«¯æŒ‰ Enter ç»§ç»­ã€‚")
    await page.goto("https://www.amazon.com.au/", timeout=60000, wait_until="domcontentloaded")
    await page.wait_for_timeout(2000)
    input("ğŸ‘‰ è¯·æ‰‹åŠ¨ä¿®æ”¹åœ°å€å®ŒæˆåæŒ‰ Enter é”®ç»§ç»­æŠ“å–...")


# --------- å•†å“ä¿¡æ¯æå–é€»è¾‘ ---------
async def fetch_product(page, url):
    """æ‰“å¼€å•†å“é¡µå¹¶è§£æå­—æ®µï¼ˆå¼ºåŒ–ç‰ˆï¼šå…¼å®¹æ—§å¼ Buy Boxï¼Œä¸¤è¡Œæ–‡æœ¬è§£æï¼‰"""
    try:
        await page.goto(url, timeout=60000, wait_until="domcontentloaded")
        await page.wait_for_selector("#productTitle", timeout=30000)
        await page.evaluate("window.scrollBy(0, 400)")
        await page.wait_for_timeout(1000)
        html = await page.content()
        soup = BeautifulSoup(html, "lxml")

        data = {"é“¾æ¥": url}

        # ---------- ASIN ----------
        m = re.search(r"/dp/([A-Z0-9]{10})", url)
        data["äºšé©¬é€ŠASIN"] = m.group(1) if m else "â€”"

        # ---------- ä»·æ ¼ ----------
        price = None
        for sel in [
            "#corePrice_feature_div .a-price .a-offscreen",
            "#apex_desktop .a-price .a-offscreen",
            "#corePrice_desktop_feature_div .a-price .a-offscreen",
            "#price_inside_buybox",
            "span.a-price .a-offscreen",
        ]:
            el = soup.select_one(sel)
            if el and "$" in el.get_text():
                price = el.get_text(strip=True)
                break
        if not price:
            for el in soup.select("span.a-offscreen"):
                parent = el.find_parent()
                pid = parent.get("id") if parent else ""
                if pid and re.search(r"(installment|emi)", pid, re.I):
                    continue
                txt = el.get_text(strip=True)
                if "$" in txt and re.search(r"\$\s?\d", txt) and len(txt) < 24:
                    price = txt
                    break
        if not price:
            whole = soup.select_one("span.a-price-whole")
            frac = soup.select_one("span.a-price-fraction")
            sym  = soup.select_one("span.a-price-symbol")
            if whole:
                price = (sym.get_text(strip=True) if sym else "$") + whole.get_text(strip=True)
                if frac:
                    price += "." + frac.get_text(strip=True)
        data["ä»·æ ¼"] = clean_text(price)

        # ---------- è¯„åˆ† ----------
        rating_el = (
            soup.select_one("span[data-hook='rating-out-of-text']")
            or soup.select_one("i[data-hook='average-star-rating'] span")
            or soup.select_one("span.a-icon-alt")
        )
        data["è¯„åˆ†"] = clean_text(rating_el.get_text(strip=True) if rating_el else None)

        # ---------- review æ•°é‡ ----------
        rc_el = (
            soup.select_one("#acrCustomerReviewText")
            or soup.select_one("span#acrCustomerReviewText")
            or soup.select_one("[data-hook='total-review-count']")
            or soup.select_one("#acrPopover .a-size-base")
        )
        data["reviewæ•°é‡"] = clean_text(rc_el.get_text(strip=True) if rc_el else None)

        # ---------- åº—é“ºåç§° + FBAï¼ˆç¨³ï¼šä¼˜å…ˆå–åŒè¡Œ <a> æ–‡æœ¬ï¼Œå¹¶åšæ ‡å‡†åŒ–å»é‡ï¼‰ ----------
        def _normalize_value(s: str) -> str:
            s = clean_text(s)
            # å»æ‰å‰ç¼€æ ‡ç­¾
            s = re.sub(r'(?i)\b(sold\s*by|ships\s*from)\b[:ï¼š]?\s*', '', s)
            # åªä¿ç•™ç¬¬ä¸€ä¸ªâ€œand/&â€ä¹‹å‰çš„å–å®¶åï¼ˆé¿å… "X and Y"ï¼‰
            s = re.split(r'\s+(?:and|&)\s+', s, maxsplit=1, flags=re.I)[0]
            # åˆå¹¶é‡å¤è¯ï¼ˆé¿å… "Conglin AU AU"ï¼‰
            parts = s.split()
            dedup = []
            for w in parts:
                if not dedup or w != dedup[-1]:
                    dedup.append(w)
            s = " ".join(dedup)
            # å¦‚æœæ•´ä¸²è¢«é‡å¤ä¸¤éï¼ˆ"Conglin AU Conglin AU"ï¼‰ï¼Œå–å‰åŠ
            mrep = re.match(r'^(?P<x>.+?)\s+\1$', s)
            if mrep:
                s = mrep.group('x')
            return s.strip(' .') or "â€”"

        seller = "â€”"
        ships_from = "â€”"

                # ---------- åº—é“ºåç§° + FBAï¼ˆåªå–æ ‡ç­¾åçš„å€¼ï¼Œé‡åˆ°åœæ­¢è¯å³æˆªæ–­ï¼‰ ----------
        seller, ships_from = "â€”", "â€”"

        def _norm(s: str) -> str:
            s = clean_text(s)
            s = re.sub(r'(?i)\b(sold\s*by|ships\s*from)\b[:ï¼š]?\s*', '', s)  # å»æ‰æ ‡ç­¾
            s = re.split(r'\s+(?:and|&)\s+', s, 1, flags=re.I)[0]             # åªä¿ç•™ and/& å‰åŠ
            return s.strip(" .") or "â€”"

        # åœæ­¢è¯ï¼ˆé‡åˆ°è¿™äº›å°±è®¤ä¸ºæœ¬è¡Œç»“æŸï¼‰
        STOP_TOKENS = r"(?:\s{2,}|(?=Ships\s*from\b|Sold\s*by\b|Returns\b|Payment\b|Add to Wish List\b|Secure transaction\b|Eligible\b|Deliver to\b|Quantity\b|In stock\b)|\.\s|$)"
        SOLD_RE  = re.compile(r"Sold\s*by\s*[:ï¼š]?\s*(?P<val>.+?)"  + STOP_TOKENS, re.I | re.S)
        SHIPS_RE = re.compile(r"Ships\s*from\s*[:ï¼š]?\s*(?P<val>.+?)" + STOP_TOKENS, re.I | re.S)

        def _looks_ok(txt: str) -> bool:
            t = txt.lower()
            if not txt or len(txt) > 60: return False
            if any(k in t for k in ["returns","payment","secure transaction","add to wish list","quantity","deliver to"]):
                return False
            return True

        # A) æ–°ç‰ˆ tabularï¼ˆæœ‰å°±ç›´æ¥ç”¨ï¼‰
        for block in soup.select("#tabular-buybox .tabular-buybox-container, #tabular-buybox .tabular-buybox-text-row"):
            lab = block.select_one(".tabular-buybox-label")
            val = block.select_one(".tabular-buybox-text")
            if not lab or not val: continue
            label = clean_text(lab.get_text()).lower()
            value = _norm(val.get_text())
            if "sold" in label and seller == "â€”" and _looks_ok(value):
                seller = value
            elif "ships" in label and ships_from == "â€”" and _looks_ok(value):
                ships_from = value

        # B) æ—§å¼ä¸¤è¡Œæ–‡æœ¬ï¼ˆä¸¥æ ¼ï¼šåªåœ¨è¯¥å—é‡Œç”¨â€œSold by/Ships fromâ€åçš„å€¼ï¼Œé‡åœæ­¢è¯æˆªæ–­ï¼‰
        if seller == "â€”" or ships_from == "â€”":
            for box_sel in ["#shipsFromSoldBy_feature_div", "#desktop_buybox", "#rightCol", "#buybox_feature_div"]:
                box = soup.select_one(box_sel)
                if not box: 
                    continue
                txt = clean_text(box.get_text(" ", strip=True))

                if ships_from == "â€”":
                    m1 = SHIPS_RE.search(txt)
                    if m1:
                        v = _norm(m1.group("val"))
                        if _looks_ok(v):
                            ships_from = v

                if seller == "â€”":
                    m2 = SOLD_RE.search(txt)
                    if m2:
                        v = _norm(m2.group("val"))
                        if _looks_ok(v):
                            seller = v

        # C) merchant-info å…œåº•
        if seller == "â€”":
            mi = soup.select_one("#merchant-info")
            if mi:
                m = SOLD_RE.search(clean_text(mi.get_text(" ", strip=True)))
                if m:
                    v = _norm(m.group("val"))
                    if _looks_ok(v):
                        seller = v

        data["åº—é“ºåç§°"] = seller

        # ---------- æ˜¯å¦FBA ----------
        is_fba = "å¦"
        if ships_from != "â€”" and "amazon" in ships_from.lower():
            is_fba = "æ˜¯"
        else:
            blob = " ".join([
                soup.select_one("#merchant-info").get_text(" ", strip=True) if soup.select_one("#merchant-info") else "",
                soup.select_one("#tabular-buybox").get_text(" ", strip=True) if soup.select_one("#tabular-buybox") else "",
                soup.select_one("#shipsFromSoldBy_feature_div").get_text(" ", strip=True) if soup.select_one("#shipsFromSoldBy_feature_div") else "",
                soup.select_one("#desktop_buybox").get_text(" ", strip=True) if soup.select_one("#desktop_buybox") else "",
            ]).lower()
            if any(k in blob for k in ["fulfilled by amazon","ships from amazon","dispatched by amazon","delivered by amazon"]):
                is_fba = "æ˜¯"
        data["æ˜¯å¦FBA"] = is_fba



        # ---------- ç±»ç›®&æ’å ----------
        bsr = "â€”"
        for sel in ["#detailBullets_feature_div", "#productDetails_detailBullets_sections1", "#prodDetails"]:
            node = soup.select_one(sel)
            if not node:
                continue
            text = node.get_text(" ", strip=True)
            mm = re.search(r"Best\s*Sellers?\s*Rank\s*:?\s*(.+?)(?:Date First Available|Customer Reviews|ASIN|$)", text, flags=re.I)
            if mm:
                bsr = clean_text(mm.group(1))
                break
        if bsr == "â€”":
            crumbs = [a.get_text(strip=True) for a in soup.select("#wayfinding-breadcrumbs_feature_div a")]
            if crumbs:
                bsr = " / ".join([c for c in crumbs if c])
        data["ç±»ç›®&æ’å"] = bsr

        # ---------- review æƒ…å†µ ----------
        rv = (
            soup.select_one("div[data-hook='review'] span[data-hook='review-title'] span")
            or soup.select_one("div[data-hook='review'] span[data-hook='review-body'] span")
        )
        if rv:
            txt = rv.get_text(strip=True)
            data["reviewæƒ…å†µ"] = clean_text(txt[:120] + ("..." if len(txt) > 120 else ""))
        else:
            data["reviewæƒ…å†µ"] = "â€”"

        return data

    except Exception as e:
        print(f"[ERROR] {url} æŠ“å–å¤±è´¥ï¼š{e}")
        return None




# --------- ä¸»æµç¨‹ ---------
async def main():
    # è¯»å–é“¾æ¥
    with open("urls.txt", "r", encoding="utf-8") as f:
        urls = [line.strip() for line in f if line.strip()]

    results = []
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)  # æ”¹ True å¯éšè—æµè§ˆå™¨
        context = await browser.new_context(locale="en-AU", viewport={"width": 1280, "height": 900})
        page = await context.new_page()

        # æ‰‹åŠ¨ä¿®æ”¹åœ°å€
        await set_au_delivery_address(page)

        for url in tqdm(urls, desc="æŠ“å–è¿›åº¦", unit="item"):
            data = await fetch_product(page, url)
            if data:
                results.append(data)
            await asyncio.sleep(2 + (random.random() * 2))

        await browser.close()

    # è¾“å‡º CSV
    if results:
        df = pd.DataFrame(
            results,
            columns=["é“¾æ¥", "äºšé©¬é€ŠASIN", "ä»·æ ¼", "ç±»ç›®&æ’å", "è¯„åˆ†", "åº—é“ºåç§°", "æ˜¯å¦FBA", "reviewæ•°é‡", "reviewæƒ…å†µ"],
        )
        df.to_csv("firemaple_playwright.csv", index=False, encoding="utf-8-sig")
        print(f"[DONE] å…±ä¿å­˜ {len(df)} æ¡å•†å“æ•°æ®åˆ°æ–‡ä»¶ï¼šfiremaple_playwright.csv")
    else:
        print("[ERROR] æ²¡æœ‰æˆåŠŸæŠ“å–åˆ°ä»»ä½•å•†å“ä¿¡æ¯ã€‚")


if __name__ == "__main__":
    asyncio.run(main())

